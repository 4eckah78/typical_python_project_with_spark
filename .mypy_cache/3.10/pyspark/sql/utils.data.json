{".class": "MypyFile", "_fullname": "pyspark.sql.utils", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "AnalysisException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.AnalysisException", "kind": "Gdef"}, "Any": {".class": "SymbolTableNode", "cross_ref": "typing.Any", "kind": "Gdef"}, "Callable": {".class": "SymbolTableNode", "cross_ref": "typing.Callable", "kind": "Gdef"}, "DataFrame": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.dataframe.DataFrame", "kind": "Gdef"}, "ForeachBatchFunction": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.utils.ForeachBatchFunction", "name": "ForeachBatchFunction", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.utils.ForeachBatchFunction", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.utils", "mro": ["pyspark.sql.utils.ForeachBatchFunction", "builtins.object"], "names": {".class": "SymbolTable", "Java": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.utils.ForeachBatchFunction.Java", "name": "Java", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.utils.ForeachBatchFunction.Java", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.utils", "mro": ["pyspark.sql.utils.ForeachBatchFunction.Java", "builtins.object"], "names": {".class": "SymbolTable", "implements": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "pyspark.sql.utils.ForeachBatchFunction.Java.implements", "name": "implements", "type": {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "session", "func"], "flags": [], "fullname": "pyspark.sql.utils.ForeachBatchFunction.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "session", "func"], "arg_types": ["pyspark.sql.utils.ForeachBatchFunction", "pyspark.sql.session.SparkSession", {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": [null, null], "arg_types": ["pyspark.sql.dataframe.DataFrame", "builtins.int"], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": null, "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of ForeachBatchFunction", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "call": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "jdf", "batch_id"], "flags": [], "fullname": "pyspark.sql.utils.ForeachBatchFunction.call", "name": "call", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "jdf", "batch_id"], "arg_types": ["pyspark.sql.utils.ForeachBatchFunction", {".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaObject", "source_any": null, "type_of_any": 3}, "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "call of ForeachBatchFunction", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "error": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.utils.ForeachBatchFunction.error", "name": "error", "type": "builtins.Exception"}}, "func": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.utils.ForeachBatchFunction.func", "name": "func", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": [null, null], "arg_types": ["pyspark.sql.dataframe.DataFrame", "builtins.int"], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": null, "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "session": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.utils.ForeachBatchFunction.session", "name": "session", "type": "pyspark.sql.session.SparkSession"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "FuncT": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeVarExpr", "fullname": "pyspark.sql.utils.FuncT", "name": "FuncT", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}}, "IllegalArgumentException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.IllegalArgumentException", "kind": "Gdef"}, "JavaArray": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready", "is_inferred"], "fullname": "pyspark.sql.utils.JavaArray", "name": "JavaArray", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaArray", "source_any": null, "type_of_any": 3}}}, "JavaClass": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready", "is_inferred"], "fullname": "pyspark.sql.utils.JavaClass", "name": "JavaClass", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaClass", "source_any": null, "type_of_any": 3}}}, "JavaGateway": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready", "is_inferred"], "fullname": "pyspark.sql.utils.JavaGateway", "name": "JavaGateway", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaGateway", "source_any": null, "type_of_any": 3}}}, "JavaObject": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready", "is_inferred"], "fullname": "pyspark.sql.utils.JavaObject", "name": "JavaObject", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaObject", "source_any": null, "type_of_any": 3}}}, "Optional": {".class": "SymbolTableNode", "cross_ref": "typing.Optional", "kind": "Gdef"}, "ParseException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.ParseException", "kind": "Gdef"}, "PythonException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.PythonException", "kind": "Gdef"}, "QueryExecutionException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.QueryExecutionException", "kind": "Gdef"}, "Sequence": {".class": "SymbolTableNode", "cross_ref": "typing.Sequence", "kind": "Gdef"}, "SparkContext": {".class": "SymbolTableNode", "cross_ref": "pyspark.context.SparkContext", "kind": "Gdef"}, "SparkSession": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.session.SparkSession", "kind": "Gdef"}, "SparkUpgradeException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.SparkUpgradeException", "kind": "Gdef"}, "StreamingQueryException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.StreamingQueryException", "kind": "Gdef"}, "TYPE_CHECKING": {".class": "SymbolTableNode", "cross_ref": "typing.TYPE_CHECKING", "kind": "Gdef"}, "TypeVar": {".class": "SymbolTableNode", "cross_ref": "typing.TypeVar", "kind": "Gdef"}, "UnknownException": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.UnknownException", "kind": "Gdef"}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.utils.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.utils.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.utils.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.utils.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.utils.__package__", "name": "__package__", "type": "builtins.str"}}, "_find_spark_home": {".class": "SymbolTableNode", "cross_ref": "pyspark.find_spark_home._find_spark_home", "kind": "Gdef"}, "cast": {".class": "SymbolTableNode", "cross_ref": "typing.cast", "kind": "Gdef"}, "functools": {".class": "SymbolTableNode", "cross_ref": "functools", "kind": "Gdef"}, "get_active_spark_context": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [], "arg_names": [], "flags": [], "fullname": "pyspark.sql.utils.get_active_spark_context", "name": "get_active_spark_context", "type": {".class": "CallableType", "arg_kinds": [], "arg_names": [], "arg_types": [], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "get_active_spark_context", "ret_type": "pyspark.context.SparkContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "has_numpy": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "pyspark.sql.utils.has_numpy", "name": "has_numpy", "type": "builtins.bool"}}, "is_remote": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [], "arg_names": [], "flags": [], "fullname": "pyspark.sql.utils.is_remote", "name": "is_remote", "type": {".class": "CallableType", "arg_kinds": [], "arg_names": [], "arg_types": [], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "is_remote", "ret_type": "builtins.bool", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "is_timestamp_ntz_preferred": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [], "arg_names": [], "flags": [], "fullname": "pyspark.sql.utils.is_timestamp_ntz_preferred", "name": "is_timestamp_ntz_preferred", "type": {".class": "CallableType", "arg_kinds": [], "arg_names": [], "arg_types": [], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "is_timestamp_ntz_preferred", "ret_type": "builtins.bool", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "np": {".class": "SymbolTableNode", "cross_ref": "numpy", "kind": "Gdef"}, "os": {".class": "SymbolTableNode", "cross_ref": "os", "kind": "Gdef"}, "require_test_compiled": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [], "arg_names": [], "flags": [], "fullname": "pyspark.sql.utils.require_test_compiled", "name": "require_test_compiled", "type": {".class": "CallableType", "arg_kinds": [], "arg_names": [], "arg_types": [], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "require_test_compiled", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "toJArray": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["gateway", "jtype", "arr"], "flags": [], "fullname": "pyspark.sql.utils.toJArray", "name": "toJArray", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["gateway", "jtype", "arr"], "arg_types": [{".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaGateway", "source_any": null, "type_of_any": 3}, {".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaClass", "source_any": null, "type_of_any": 3}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "typing.Sequence"}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "toJArray", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.utils.JavaArray", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "to_str": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["value"], "flags": [], "fullname": "pyspark.sql.utils.to_str", "name": "to_str", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["value"], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "to_str", "ret_type": {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "try_remote_functions": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["f"], "flags": [], "fullname": "pyspark.sql.utils.try_remote_functions", "name": "try_remote_functions", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["f"], "arg_types": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "try_remote_functions", "ret_type": {".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}, "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}]}}}, "try_remote_observation": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["f"], "flags": [], "fullname": "pyspark.sql.utils.try_remote_observation", "name": "try_remote_observation", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["f"], "arg_types": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "try_remote_observation", "ret_type": {".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}, "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}]}}}, "try_remote_window": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["f"], "flags": [], "fullname": "pyspark.sql.utils.try_remote_window", "name": "try_remote_window", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["f"], "arg_types": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "try_remote_window", "ret_type": {".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}, "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}]}}}, "try_remote_windowspec": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["f"], "flags": [], "fullname": "pyspark.sql.utils.try_remote_windowspec", "name": "try_remote_windowspec", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["f"], "arg_types": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "try_remote_windowspec", "ret_type": {".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}, "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql.utils.FuncT", "id": -1, "name": "FuncT", "namespace": "", "upper_bound": {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, "values": [], "variance": 0}]}}}}, "path": "C:\\Users\\Egor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\utils.py"}