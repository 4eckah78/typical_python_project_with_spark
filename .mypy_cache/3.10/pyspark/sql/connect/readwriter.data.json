{".class": "MypyFile", "_fullname": "pyspark.sql.connect.readwriter", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "ColumnOrName": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect._typing.ColumnOrName", "kind": "Gdef", "module_public": false}, "DataFrame": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.dataframe.DataFrame", "kind": "Gdef", "module_public": false}, "DataFrameReader": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["pyspark.sql.connect.readwriter.OptionUtils"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.readwriter.DataFrameReader", "name": "DataFrameReader", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.readwriter", "mro": ["pyspark.sql.connect.readwriter.DataFrameReader", "pyspark.sql.connect.readwriter.OptionUtils", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "client"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "client"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "pyspark.sql.connect.session.SparkSession"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of DataFrameReader", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_client": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader._client", "name": "_client", "type": "pyspark.sql.connect.session.SparkSession"}}, "_df": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "plan"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader._df", "name": "_df", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "plan"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "pyspark.sql.connect.plan.LogicalPlan"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_df of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_format": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader._format", "name": "_format", "type": {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}}}, "_jreader": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader._jreader", "name": "_jreader", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_jreader of DataFrameReader", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader._jreader", "name": "_jreader", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_jreader of DataFrameReader", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_options": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader._options", "name": "_options", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}, "_schema": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader._schema", "name": "_schema", "type": "builtins.str"}}, "csv": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "schema", "sep", "encoding", "quote", "escape", "comment", "header", "inferSchema", "ignoreLeadingWhiteSpace", "ignoreTrailingWhiteSpace", "nullValue", "nanValue", "positiveInf", "negativeInf", "dateFormat", "timestampFormat", "maxColumns", "maxCharsPerColumn", "maxMalformedLogPerPartition", "mode", "columnNameOfCorruptRecord", "multiLine", "charToEscapeQuoteEscaping", "samplingRatio", "enforceSchema", "emptyValue", "locale", "lineSep", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter", "unescapedQuoteHandling"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.csv", "name": "csv", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "schema", "sep", "encoding", "quote", "escape", "comment", "header", "inferSchema", "ignoreLeadingWhiteSpace", "ignoreTrailingWhiteSpace", "nullValue", "nanValue", "positiveInf", "negativeInf", "dateFormat", "timestampFormat", "maxColumns", "maxCharsPerColumn", "maxMalformedLogPerPartition", "mode", "columnNameOfCorruptRecord", "multiLine", "charToEscapeQuoteEscaping", "samplingRatio", "enforceSchema", "emptyValue", "locale", "lineSep", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter", "unescapedQuoteHandling"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.PathOrPaths"}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.int", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.int", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.int", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.float", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "csv of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "format": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "source"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.format", "name": "format", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "source"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "format of DataFrameReader", "ret_type": "pyspark.sql.connect.readwriter.DataFrameReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "jdbc": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "OverloadedFuncDef", "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "impl": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "url", "table", "column", "lowerBound", "upperBound", "numPartitions", "predicates", "properties"], "flags": ["is_overload"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "name": "jdbc", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "url", "table", "column", "lowerBound", "upperBound", "numPartitions", "predicates", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.int", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.int", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.int", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "items": [{".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 5], "arg_names": ["self", "url", "table", "properties"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "name": "jdbc", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 5], "arg_names": ["self", "url", "table", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", "builtins.str", {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "name": "jdbc", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0, 0, 0, 0, 5], "arg_names": ["self", "url", "table", "column", "lowerBound", "upperBound", "numPartitions", "properties"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "name": "jdbc", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0, 0, 0, 0, 5], "arg_names": ["self", "url", "table", "column", "lowerBound", "upperBound", "numPartitions", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", "builtins.str", "builtins.str", {".class": "UnionType", "items": ["builtins.int", "builtins.str"]}, {".class": "UnionType", "items": ["builtins.int", "builtins.str"]}, "builtins.int", {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "name": "jdbc", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 3, 5], "arg_names": ["self", "url", "table", "predicates", "properties"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "name": "jdbc", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 3, 5], "arg_names": ["self", "url", "table", "predicates", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", "builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.jdbc", "name": "jdbc", "type": null}}], "type": {".class": "Overloaded", "items": [{".class": "CallableType", "arg_kinds": [0, 0, 0, 5], "arg_names": ["self", "url", "table", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", "builtins.str", {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "CallableType", "arg_kinds": [0, 0, 0, 0, 0, 0, 0, 5], "arg_names": ["self", "url", "table", "column", "lowerBound", "upperBound", "numPartitions", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", "builtins.str", "builtins.str", {".class": "UnionType", "items": ["builtins.int", "builtins.str"]}, {".class": "UnionType", "items": ["builtins.int", "builtins.str"]}, "builtins.int", {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "CallableType", "arg_kinds": [0, 0, 0, 3, 5], "arg_names": ["self", "url", "table", "predicates", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", "builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}]}}}, "json": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "schema", "primitivesAsString", "prefersDecimal", "allowComments", "allowUnquotedFieldNames", "allowSingleQuotes", "allowNumericLeadingZero", "allowBackslashEscapingAnyCharacter", "mode", "columnNameOfCorruptRecord", "dateFormat", "timestampFormat", "multiLine", "allowUnquotedControlChars", "lineSep", "samplingRatio", "dropFieldIfAllNull", "encoding", "locale", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter", "allowNonNumericNumbers"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.json", "name": "json", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "schema", "primitivesAsString", "prefersDecimal", "allowComments", "allowUnquotedFieldNames", "allowSingleQuotes", "allowNumericLeadingZero", "allowBackslashEscapingAnyCharacter", "mode", "columnNameOfCorruptRecord", "dateFormat", "timestampFormat", "multiLine", "allowUnquotedControlChars", "lineSep", "samplingRatio", "dropFieldIfAllNull", "encoding", "locale", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter", "allowNonNumericNumbers"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.PathOrPaths"}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.float", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "json of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "load": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 4], "arg_names": ["self", "path", "format", "schema", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.load", "name": "load", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 4], "arg_names": ["self", "path", "format", "schema", "options"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", {".class": "UnionType", "items": ["builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str", {".class": "NoneType"}]}, {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "load of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "option": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.option", "name": "option", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "option of DataFrameReader", "ret_type": "pyspark.sql.connect.readwriter.DataFrameReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "options": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 4], "arg_names": ["self", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.options", "name": "options", "type": {".class": "CallableType", "arg_kinds": [0, 4], "arg_names": ["self", "options"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "options of DataFrameReader", "ret_type": "pyspark.sql.connect.readwriter.DataFrameReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "orc": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "mergeSchema", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.orc", "name": "orc", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "mergeSchema", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.PathOrPaths"}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "orc of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "parquet": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 2, 4], "arg_names": ["self", "paths", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.parquet", "name": "parquet", "type": {".class": "CallableType", "arg_kinds": [0, 2, 4], "arg_names": ["self", "paths", "options"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "parquet of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "schema": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "schema"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.schema", "name": "schema", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "schema"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str"]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "schema of DataFrameReader", "ret_type": "pyspark.sql.connect.readwriter.DataFrameReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "table": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.table", "name": "table", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "table of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "text": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "paths", "wholetext", "lineSep", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameReader.text", "name": "text", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "paths", "wholetext", "lineSep", "pathGlobFilter", "recursiveFileLookup", "modifiedBefore", "modifiedAfter"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameReader", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.PathOrPaths"}, {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "text of DataFrameReader", "ret_type": "pyspark.sql.connect.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "DataFrameWriter": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["pyspark.sql.connect.readwriter.OptionUtils"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter", "name": "DataFrameWriter", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.readwriter", "mro": ["pyspark.sql.connect.readwriter.DataFrameWriter", "pyspark.sql.connect.readwriter.OptionUtils", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "plan", "session"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "plan", "session"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "pyspark.sql.connect.plan.LogicalPlan", "pyspark.sql.connect.session.SparkSession"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_df": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter._df", "name": "_df", "type": "pyspark.sql.connect.plan.LogicalPlan"}}, "_spark": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter._spark", "name": "_spark", "type": "pyspark.sql.connect.session.SparkSession"}}, "_write": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter._write", "name": "_write", "type": "pyspark.sql.connect.plan.WriteOperation"}}, "bucketBy": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "OverloadedFuncDef", "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.bucketBy", "impl": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 2], "arg_names": ["self", "numBuckets", "col", "cols"], "flags": ["is_overload"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.bucketBy", "name": "bucketBy", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 2], "arg_names": ["self", "numBuckets", "col", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.int", {".class": "UnionType", "items": ["builtins.str", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.TupleOrListOfString"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucketBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "items": [{".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 2], "arg_names": ["self", "numBuckets", "col", "cols"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.bucketBy", "name": "bucketBy", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 2], "arg_names": ["self", "numBuckets", "col", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.int", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucketBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.bucketBy", "name": "bucketBy", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "numBuckets", "col"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.bucketBy", "name": "bucketBy", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "numBuckets", "col"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.int", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.TupleOrListOfString"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucketBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.bucketBy", "name": "bucketBy", "type": null}}], "type": {".class": "Overloaded", "items": [{".class": "CallableType", "arg_kinds": [0, 0, 0, 2], "arg_names": ["self", "numBuckets", "col", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.int", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucketBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "numBuckets", "col"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.int", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.TupleOrListOfString"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucketBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}]}}}, "csv": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "mode", "compression", "sep", "quote", "escape", "header", "nullValue", "escapeQuotes", "quoteAll", "dateFormat", "timestampFormat", "ignoreLeadingWhiteSpace", "ignoreTrailingWhiteSpace", "charToEscapeQuoteEscaping", "encoding", "emptyValue", "lineSep"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.csv", "name": "csv", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "mode", "compression", "sep", "quote", "escape", "header", "nullValue", "escapeQuotes", "quoteAll", "dateFormat", "timestampFormat", "ignoreLeadingWhiteSpace", "ignoreTrailingWhiteSpace", "charToEscapeQuoteEscaping", "encoding", "emptyValue", "lineSep"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "csv of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "format": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "source"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.format", "name": "format", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "source"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "format of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "insertInto": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "tableName", "overwrite"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.insertInto", "name": "insertInto", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "tableName", "overwrite"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "UnionType", "items": ["builtins.bool", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "insertInto of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "jdbc": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 1, 1], "arg_names": ["self", "url", "table", "mode", "properties"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.jdbc", "name": "jdbc", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 1, 1], "arg_names": ["self", "url", "table", "mode", "properties"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "jdbc of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "json": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "mode", "compression", "dateFormat", "timestampFormat", "lineSep", "encoding", "ignoreNullFields"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.json", "name": "json", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 1, 1, 1, 1], "arg_names": ["self", "path", "mode", "compression", "dateFormat", "timestampFormat", "lineSep", "encoding", "ignoreNullFields"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.bool", "builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "json of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "mode": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "saveMode"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.mode", "name": "mode", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "saveMode"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "mode of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "option": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.option", "name": "option", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "option of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "options": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 4], "arg_names": ["self", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.options", "name": "options", "type": {".class": "CallableType", "arg_kinds": [0, 4], "arg_names": ["self", "options"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "options of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "orc": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "path", "mode", "partitionBy", "compression"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.orc", "name": "orc", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "path", "mode", "partitionBy", "compression"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "orc of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "parquet": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "path", "mode", "partitionBy", "compression"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.parquet", "name": "parquet", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "path", "mode", "partitionBy", "compression"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "parquet of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "partitionBy": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "OverloadedFuncDef", "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.partitionBy", "impl": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "flags": ["is_overload"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.partitionBy", "name": "partitionBy", "type": {".class": "CallableType", "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "UnionType", "items": ["builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitionBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "items": [{".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.partitionBy", "name": "partitionBy", "type": {".class": "CallableType", "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitionBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.partitionBy", "name": "partitionBy", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.partitionBy", "name": "partitionBy", "type": {".class": "CallableType", "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitionBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.partitionBy", "name": "partitionBy", "type": null}}], "type": {".class": "Overloaded", "items": [{".class": "CallableType", "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitionBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "CallableType", "arg_kinds": [0, 2], "arg_names": ["self", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitionBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}]}}}, "save": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 1, 1, 1, 4], "arg_names": ["self", "path", "format", "mode", "partitionBy", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.save", "name": "save", "type": {".class": "CallableType", "arg_kinds": [0, 1, 1, 1, 1, 4], "arg_names": ["self", "path", "format", "mode", "partitionBy", "options"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "save of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "saveAsTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 4], "arg_names": ["self", "name", "format", "mode", "partitionBy", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.saveAsTable", "name": "saveAsTable", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 4], "arg_names": ["self", "name", "format", "mode", "partitionBy", "options"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}, {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "saveAsTable of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "sortBy": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "OverloadedFuncDef", "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.sortBy", "impl": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 2], "arg_names": ["self", "col", "cols"], "flags": ["is_overload"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.sortBy", "name": "sortBy", "type": {".class": "CallableType", "arg_kinds": [0, 0, 2], "arg_names": ["self", "col", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "UnionType", "items": ["builtins.str", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.TupleOrListOfString"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sortBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "items": [{".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 2], "arg_names": ["self", "col", "cols"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.sortBy", "name": "sortBy", "type": {".class": "CallableType", "arg_kinds": [0, 0, 2], "arg_names": ["self", "col", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sortBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.sortBy", "name": "sortBy", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "col"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.sortBy", "name": "sortBy", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "col"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.TupleOrListOfString"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sortBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.sortBy", "name": "sortBy", "type": null}}], "type": {".class": "Overloaded", "items": [{".class": "CallableType", "arg_kinds": [0, 0, 2], "arg_names": ["self", "col", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sortBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "col"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect.readwriter.TupleOrListOfString"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sortBy of DataFrameWriter", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriter", "type_guard": null, "unpack_kwargs": false, "variables": []}]}}}, "text": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "path", "compression", "lineSep"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriter.text", "name": "text", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "path", "compression", "lineSep"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriter", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "text of DataFrameWriter", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "DataFrameWriterV2": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["pyspark.sql.connect.readwriter.OptionUtils"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2", "name": "DataFrameWriterV2", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.readwriter", "mro": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", "pyspark.sql.connect.readwriter.OptionUtils", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "plan", "session", "table"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 0], "arg_names": ["self", "plan", "session", "table"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", "pyspark.sql.connect.plan.LogicalPlan", "pyspark.sql.connect.session.SparkSession", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of DataFrameWriterV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_df": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2._df", "name": "_df", "type": "pyspark.sql.connect.plan.LogicalPlan"}}, "_spark": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2._spark", "name": "_spark", "type": "pyspark.sql.connect.session.SparkSession"}}, "_table_name": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2._table_name", "name": "_table_name", "type": "builtins.str"}}, "_write": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["explicit_self_type", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2._write", "name": "_write", "type": "pyspark.sql.connect.plan.WriteOperationV2"}}, "append": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.append", "name": "append", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "append of DataFrameWriterV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "create": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.create", "name": "create", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "create of DataFrameWriterV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "createOrReplace": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.createOrReplace", "name": "createOrReplace", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createOrReplace of DataFrameWriterV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "option": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.option", "name": "option", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", "builtins.str", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "option of DataFrameWriterV2", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriterV2", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "options": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 4], "arg_names": ["self", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.options", "name": "options", "type": {".class": "CallableType", "arg_kinds": [0, 4], "arg_names": ["self", "options"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "options of DataFrameWriterV2", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriterV2", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "overwrite": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "condition"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.overwrite", "name": "overwrite", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "condition"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.ColumnOrName"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "overwrite of DataFrameWriterV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "overwritePartitions": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.overwritePartitions", "name": "overwritePartitions", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "overwritePartitions of DataFrameWriterV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "partitionedBy": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 2], "arg_names": ["self", "col", "cols"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.partitionedBy", "name": "partitionedBy", "type": {".class": "CallableType", "arg_kinds": [0, 0, 2], "arg_names": ["self", "col", "cols"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.ColumnOrName"}, {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.ColumnOrName"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitionedBy of DataFrameWriterV2", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriterV2", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "replace": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.replace", "name": "replace", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "replace of DataFrameWriterV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "tableProperty": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "property", "value"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.tableProperty", "name": "tableProperty", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "property", "value"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "tableProperty of DataFrameWriterV2", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriterV2", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "using": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "provider"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.DataFrameWriterV2.using", "name": "using", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "provider"], "arg_types": ["pyspark.sql.connect.readwriter.DataFrameWriterV2", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "using of DataFrameWriterV2", "ret_type": "pyspark.sql.connect.readwriter.DataFrameWriterV2", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "DataSource": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.plan.DataSource", "kind": "Gdef", "module_public": false}, "Dict": {".class": "SymbolTableNode", "cross_ref": "typing.Dict", "kind": "Gdef", "module_public": false}, "List": {".class": "SymbolTableNode", "cross_ref": "typing.List", "kind": "Gdef", "module_public": false}, "LogicalPlan": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.plan.LogicalPlan", "kind": "Gdef", "module_public": false}, "OptionUtils": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.readwriter.OptionUtils", "name": "OptionUtils", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.readwriter.OptionUtils", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.readwriter", "mro": ["pyspark.sql.connect.readwriter.OptionUtils", "builtins.object"], "names": {".class": "SymbolTable", "_set_opts": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1, 4], "arg_names": ["self", "schema", "options"], "flags": [], "fullname": "pyspark.sql.connect.readwriter.OptionUtils._set_opts", "name": "_set_opts", "type": {".class": "CallableType", "arg_kinds": [0, 1, 4], "arg_names": ["self", "schema", "options"], "arg_types": ["pyspark.sql.connect.readwriter.OptionUtils", {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str", {".class": "NoneType"}]}, {".class": "TypeAliasType", "args": [], "type_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType"}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_set_opts of OptionUtils", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "Optional": {".class": "SymbolTableNode", "cross_ref": "typing.Optional", "kind": "Gdef", "module_public": false}, "OptionalPrimitiveType": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect._typing.OptionalPrimitiveType", "kind": "Gdef", "module_public": false}, "PathOrPaths": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "TypeAlias", "alias_tvars": [], "column": 0, "fullname": "pyspark.sql.connect.readwriter.PathOrPaths", "line": 42, "no_args": false, "normalized": false, "target": {".class": "UnionType", "items": ["builtins.str", {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}]}}}, "PySparkAttributeError": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.base.PySparkAttributeError", "kind": "Gdef", "module_public": false}, "PySparkDataFrameReader": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.readwriter.DataFrameReader", "kind": "Gdef", "module_public": false}, "PySparkDataFrameWriter": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.readwriter.DataFrameWriter", "kind": "Gdef", "module_public": false}, "PySparkDataFrameWriterV2": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.readwriter.DataFrameWriterV2", "kind": "Gdef", "module_public": false}, "Read": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.plan.Read", "kind": "Gdef", "module_public": false}, "SparkSession": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.session.SparkSession", "kind": "Gdef", "module_public": false}, "StructType": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.types.StructType", "kind": "Gdef", "module_public": false}, "TYPE_CHECKING": {".class": "SymbolTableNode", "cross_ref": "typing.TYPE_CHECKING", "kind": "Gdef", "module_public": false}, "Tuple": {".class": "SymbolTableNode", "cross_ref": "typing.Tuple", "kind": "Gdef", "module_public": false}, "TupleOrListOfString": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "TypeAlias", "alias_tvars": [], "column": 0, "fullname": "pyspark.sql.connect.readwriter.TupleOrListOfString", "line": 43, "no_args": false, "normalized": false, "target": {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.tuple"}]}}}, "Union": {".class": "SymbolTableNode", "cross_ref": "typing.Union", "kind": "Gdef", "module_public": false}, "WriteOperation": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.plan.WriteOperation", "kind": "Gdef", "module_public": false}, "WriteOperationV2": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.plan.WriteOperationV2", "kind": "Gdef", "module_public": false}, "__all__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "pyspark.sql.connect.readwriter.__all__", "name": "__all__", "type": {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}}}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.readwriter.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.readwriter.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.readwriter.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.readwriter.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.readwriter.__package__", "name": "__package__", "type": "builtins.str"}}, "_test": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [], "arg_names": [], "flags": [], "fullname": "pyspark.sql.connect.readwriter._test", "name": "_test", "type": {".class": "CallableType", "arg_kinds": [], "arg_names": [], "arg_types": [], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_test", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "cast": {".class": "SymbolTableNode", "cross_ref": "typing.cast", "kind": "Gdef", "module_public": false}, "check_dependencies": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.connect.utils.check_dependencies", "kind": "Gdef", "module_public": false}, "overload": {".class": "SymbolTableNode", "cross_ref": "typing.overload", "kind": "Gdef", "module_public": false}, "to_str": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.utils.to_str", "kind": "Gdef", "module_public": false}}, "path": "C:\\Users\\Egor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\connect\\readwriter.py"}