{".class": "MypyFile", "_fullname": "pyspark.sql.context", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "Any": {".class": "SymbolTableNode", "cross_ref": "typing.Any", "kind": "Gdef", "module_public": false}, "AtomicType": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.types.AtomicType", "kind": "Gdef", "module_public": false}, "AtomicValue": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql._typing.AtomicValue", "kind": "Gdef", "module_public": false}, "Callable": {".class": "SymbolTableNode", "cross_ref": "typing.Callable", "kind": "Gdef", "module_public": false}, "ClassVar": {".class": "SymbolTableNode", "cross_ref": "typing.ClassVar", "kind": "Gdef", "module_public": false}, "DataFrame": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.dataframe.DataFrame", "kind": "Gdef", "module_public": false}, "DataFrameReader": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.readwriter.DataFrameReader", "kind": "Gdef", "module_public": false}, "DataStreamReader": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.streaming.readwriter.DataStreamReader", "kind": "Gdef", "module_public": false}, "DataType": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.types.DataType", "kind": "Gdef", "module_public": false}, "HiveContext": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["pyspark.sql.context.SQLContext"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.context.HiveContext", "name": "HiveContext", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.context.HiveContext", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.context", "mro": ["pyspark.sql.context.HiveContext", "pyspark.sql.context.SQLContext", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "sparkContext", "sparkSession", "jhiveContext"], "flags": [], "fullname": "pyspark.sql.context.HiveContext.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "sparkContext", "sparkSession", "jhiveContext"], "arg_types": ["pyspark.sql.context.HiveContext", "pyspark.context.SparkContext", {".class": "UnionType", "items": ["pyspark.sql.session.SparkSession", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "AnyType", "missing_import_name": "pyspark.sql.context.JavaObject", "source_any": null, "type_of_any": 3}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of HiveContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_createForTesting": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["cls", "sparkContext"], "flags": ["is_class", "is_decorated"], "fullname": "pyspark.sql.context.HiveContext._createForTesting", "name": "_createForTesting", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["cls", "sparkContext"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.HiveContext"}, "pyspark.context.SparkContext"], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_createForTesting of HiveContext", "ret_type": "pyspark.sql.context.HiveContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_classmethod", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.HiveContext._createForTesting", "name": "_createForTesting", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["cls", "sparkContext"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.HiveContext"}, "pyspark.context.SparkContext"], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_createForTesting of HiveContext", "ret_type": "pyspark.sql.context.HiveContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_get_or_create": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 4], "arg_names": ["cls", "sc", "static_conf"], "flags": ["is_class", "is_decorated"], "fullname": "pyspark.sql.context.HiveContext._get_or_create", "name": "_get_or_create", "type": {".class": "CallableType", "arg_kinds": [0, 0, 4], "arg_names": ["cls", "sc", "static_conf"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.SQLContext"}, "pyspark.context.SparkContext", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_get_or_create of HiveContext", "ret_type": "pyspark.sql.context.SQLContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_classmethod", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.HiveContext._get_or_create", "name": "_get_or_create", "type": {".class": "CallableType", "arg_kinds": [0, 0, 4], "arg_names": ["cls", "sc", "static_conf"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.SQLContext"}, "pyspark.context.SparkContext", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_get_or_create of HiveContext", "ret_type": "pyspark.sql.context.SQLContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_static_conf": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_inferred", "has_explicit_value"], "fullname": "pyspark.sql.context.HiveContext._static_conf", "name": "_static_conf", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}, "refreshTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "flags": [], "fullname": "pyspark.sql.context.HiveContext.refreshTable", "name": "refreshTable", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.context.HiveContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "refreshTable of HiveContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "Iterable": {".class": "SymbolTableNode", "cross_ref": "typing.Iterable", "kind": "Gdef", "module_public": false}, "JavaObject": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.JavaObject", "name": "JavaObject", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.context.JavaObject", "source_any": null, "type_of_any": 3}}}, "List": {".class": "SymbolTableNode", "cross_ref": "typing.List", "kind": "Gdef", "module_public": false}, "Optional": {".class": "SymbolTableNode", "cross_ref": "typing.Optional", "kind": "Gdef", "module_public": false}, "PandasDataFrameLike": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.pandas._typing.DataFrameLike", "kind": "Gdef", "module_public": false}, "RDD": {".class": "SymbolTableNode", "cross_ref": "pyspark.rdd.RDD", "kind": "Gdef", "module_public": false}, "RowLike": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql._typing.RowLike", "kind": "Gdef", "module_public": false}, "SQLContext": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.context.SQLContext", "name": "SQLContext", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.context.SQLContext", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.context", "mro": ["pyspark.sql.context.SQLContext", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "sparkContext", "sparkSession", "jsqlContext"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "sparkContext", "sparkSession", "jsqlContext"], "arg_types": ["pyspark.sql.context.SQLContext", "pyspark.context.SparkContext", {".class": "UnionType", "items": ["pyspark.sql.session.SparkSession", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "AnyType", "missing_import_name": "pyspark.sql.context.JavaObject", "source_any": null, "type_of_any": 3}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_get_or_create": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 4], "arg_names": ["cls", "sc", "static_conf"], "flags": ["is_class", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext._get_or_create", "name": "_get_or_create", "type": {".class": "CallableType", "arg_kinds": [0, 0, 4], "arg_names": ["cls", "sc", "static_conf"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.SQLContext"}, "pyspark.context.SparkContext", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_get_or_create of SQLContext", "ret_type": "pyspark.sql.context.SQLContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_classmethod", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext._get_or_create", "name": "_get_or_create", "type": {".class": "CallableType", "arg_kinds": [0, 0, 4], "arg_names": ["cls", "sc", "static_conf"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.SQLContext"}, "pyspark.context.SparkContext", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_get_or_create of SQLContext", "ret_type": "pyspark.sql.context.SQLContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "_inferSchema": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "rdd", "samplingRatio"], "flags": [], "fullname": "pyspark.sql.context.SQLContext._inferSchema", "name": "_inferSchema", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "rdd", "samplingRatio"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 4}], "type_ref": "pyspark.rdd.RDD"}, {".class": "UnionType", "items": ["builtins.float", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_inferSchema of SQLContext", "ret_type": "pyspark.sql.types.StructType", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_instantiatedContext": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_classvar", "is_ready", "has_explicit_value"], "fullname": "pyspark.sql.context.SQLContext._instantiatedContext", "name": "_instantiatedContext", "type": {".class": "UnionType", "items": ["pyspark.sql.context.SQLContext", {".class": "NoneType"}]}}}, "_jsc": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext._jsc", "name": "_jsc", "type": {".class": "AnyType", "missing_import_name": "pyspark.context.JavaObject", "source_any": null, "type_of_any": 3}}}, "_jsqlContext": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext._jsqlContext", "name": "_jsqlContext", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.context.JavaObject", "source_any": null, "type_of_any": 3}}}, "_jvm": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext._jvm", "name": "_jvm", "type": {".class": "UnionType", "items": [{".class": "AnyType", "missing_import_name": "pyspark.context.JVMView", "source_any": null, "type_of_any": 3}, {".class": "NoneType"}]}}}, "_sc": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext._sc", "name": "_sc", "type": "pyspark.context.SparkContext"}}, "_ssql_ctx": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext._ssql_ctx", "name": "_ssql_ctx", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_ssql_ctx of SQLContext", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.context.JavaObject", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext._ssql_ctx", "name": "_ssql_ctx", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_ssql_ctx of SQLContext", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.context.JavaObject", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "cacheTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "flags": ["is_decorated"], "fullname": "pyspark.sql.context.SQLContext.cacheTable", "name": "cacheTable", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "cacheTable of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.cacheTable", "name": "cacheTable", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "cacheTable of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "clearCache": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_decorated"], "fullname": "pyspark.sql.context.SQLContext.clearCache", "name": "clearCache", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "clearCache of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.clearCache", "name": "clearCache", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "clearCache of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "createDataFrame": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "OverloadedFuncDef", "flags": [], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "impl": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "data", "schema", "samplingRatio", "verifySchema"], "flags": ["is_overload"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "data", "schema", "samplingRatio", "verifySchema"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "pyspark.rdd.RDD"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "typing.Iterable"}, {".class": "UnboundType", "args": [], "expr": "PandasDataFrameLike", "expr_fallback": "builtins.str", "name": "PandasDataFrameLike"}]}, {".class": "UnionType", "items": ["pyspark.sql.types.AtomicType", "pyspark.sql.types.StructType", "builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.float", {".class": "NoneType"}]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "items": [{".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "data", "schema", "samplingRatio"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "data", "schema", "samplingRatio"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": [{".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "pyspark.rdd.RDD"}, {".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "typing.Iterable"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.tuple"}]}, {".class": "UnionType", "items": ["builtins.float", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}]}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 5], "arg_names": ["self", "data", "schema", "verifySchema"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 5], "arg_names": ["self", "data", "schema", "verifySchema"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": [{".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "pyspark.rdd.RDD"}, {".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "typing.Iterable"}]}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str"]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}]}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "data", "schema", "verifySchema"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "data", "schema", "verifySchema"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": [{".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.AtomicValue", "id": -1, "name": "AtomicValue", "namespace": "", "upper_bound": "builtins.object", "values": ["datetime.datetime", "datetime.date", "_decimal.Decimal", "builtins.bool", "builtins.str", "builtins.int", "builtins.float"], "variance": 0}], "type_ref": "pyspark.rdd.RDD"}, {".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.AtomicValue", "id": -1, "name": "AtomicValue", "namespace": "", "upper_bound": "builtins.object", "values": ["datetime.datetime", "datetime.date", "_decimal.Decimal", "builtins.bool", "builtins.str", "builtins.int", "builtins.float"], "variance": 0}], "type_ref": "typing.Iterable"}]}, {".class": "UnionType", "items": ["pyspark.sql.types.AtomicType", "builtins.str"]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.AtomicValue", "id": -1, "name": "AtomicValue", "namespace": "", "upper_bound": "builtins.object", "values": ["datetime.datetime", "datetime.date", "_decimal.Decimal", "builtins.bool", "builtins.str", "builtins.int", "builtins.float"], "variance": 0}]}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "data", "samplingRatio"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "data", "samplingRatio"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnboundType", "args": [], "expr": "PandasDataFrameLike", "expr_fallback": "builtins.str", "name": "PandasDataFrameLike"}, {".class": "UnionType", "items": ["builtins.float", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "data", "schema", "verifySchema"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "data", "schema", "verifySchema"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnboundType", "args": [], "expr": "PandasDataFrameLike", "expr_fallback": "builtins.str", "name": "PandasDataFrameLike"}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str"]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext.createDataFrame", "name": "createDataFrame", "type": null}}], "type": {".class": "Overloaded", "items": [{".class": "CallableType", "arg_kinds": [0, 0, 1, 1], "arg_names": ["self", "data", "schema", "samplingRatio"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": [{".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "pyspark.rdd.RDD"}, {".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "typing.Iterable"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.tuple"}]}, {".class": "UnionType", "items": ["builtins.float", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}]}, {".class": "CallableType", "arg_kinds": [0, 0, 0, 5], "arg_names": ["self", "data", "schema", "verifySchema"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": [{".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "pyspark.rdd.RDD"}, {".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}], "type_ref": "typing.Iterable"}]}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str"]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.RowLike", "id": -1, "name": "RowLike", "namespace": "", "upper_bound": "builtins.object", "values": [{".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.list"}, {".class": "Instance", "args": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "type_ref": "builtins.tuple"}, "pyspark.sql.types.Row"], "variance": 0}]}, {".class": "CallableType", "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "data", "schema", "verifySchema"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": [{".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.AtomicValue", "id": -1, "name": "AtomicValue", "namespace": "", "upper_bound": "builtins.object", "values": ["datetime.datetime", "datetime.date", "_decimal.Decimal", "builtins.bool", "builtins.str", "builtins.int", "builtins.float"], "variance": 0}], "type_ref": "pyspark.rdd.RDD"}, {".class": "Instance", "args": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.AtomicValue", "id": -1, "name": "AtomicValue", "namespace": "", "upper_bound": "builtins.object", "values": ["datetime.datetime", "datetime.date", "_decimal.Decimal", "builtins.bool", "builtins.str", "builtins.int", "builtins.float"], "variance": 0}], "type_ref": "typing.Iterable"}]}, {".class": "UnionType", "items": ["pyspark.sql.types.AtomicType", "builtins.str"]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": [{".class": "TypeVarType", "fullname": "pyspark.sql._typing.AtomicValue", "id": -1, "name": "AtomicValue", "namespace": "", "upper_bound": "builtins.object", "values": ["datetime.datetime", "datetime.date", "_decimal.Decimal", "builtins.bool", "builtins.str", "builtins.int", "builtins.float"], "variance": 0}]}, {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "data", "samplingRatio"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnboundType", "args": [], "expr": "PandasDataFrameLike", "expr_fallback": "builtins.str", "name": "PandasDataFrameLike"}, {".class": "UnionType", "items": ["builtins.float", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "CallableType", "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "data", "schema", "verifySchema"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnboundType", "args": [], "expr": "PandasDataFrameLike", "expr_fallback": "builtins.str", "name": "PandasDataFrameLike"}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", "builtins.str"]}, "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createDataFrame of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}]}}}, "createExternalTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1, 4], "arg_names": ["self", "tableName", "path", "source", "schema", "options"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.createExternalTable", "name": "createExternalTable", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1, 4], "arg_names": ["self", "tableName", "path", "source", "schema", "options"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["pyspark.sql.types.StructType", {".class": "NoneType"}]}, "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "createExternalTable of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "dropTempTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.dropTempTable", "name": "dropTempTable", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "dropTempTable of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "getConf": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1], "arg_names": ["self", "key", "defaultValue"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.getConf", "name": "getConf", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "key", "defaultValue"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}, "pyspark._globals._NoValueType"]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "getConf of SQLContext", "ret_type": {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "getOrCreate": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["cls", "sc"], "flags": ["is_class", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.getOrCreate", "name": "getOrCreate", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["cls", "sc"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.SQLContext"}, "pyspark.context.SparkContext"], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "getOrCreate of SQLContext", "ret_type": "pyspark.sql.context.SQLContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_classmethod", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.getOrCreate", "name": "getOrCreate", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["cls", "sc"], "arg_types": [{".class": "TypeType", "item": "pyspark.sql.context.SQLContext"}, "pyspark.context.SparkContext"], "bound_args": [], "def_extras": {"first_arg": "cls"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "getOrCreate of SQLContext", "ret_type": "pyspark.sql.context.SQLContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "newSession": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.newSession", "name": "newSession", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "newSession of SQLContext", "ret_type": "pyspark.sql.context.SQLContext", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "range": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "start", "end", "step", "numPartitions"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.range", "name": "range", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1, 1, 1], "arg_names": ["self", "start", "end", "step", "numPartitions"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.int", {".class": "UnionType", "items": ["builtins.int", {".class": "NoneType"}]}, "builtins.int", {".class": "UnionType", "items": ["builtins.int", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "range of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "read": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.read", "name": "read", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "read of SQLContext", "ret_type": "pyspark.sql.readwriter.DataFrameReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.read", "name": "read", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "read of SQLContext", "ret_type": "pyspark.sql.readwriter.DataFrameReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "readStream": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.readStream", "name": "readStream", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "readStream of SQLContext", "ret_type": "pyspark.sql.streaming.readwriter.DataStreamReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.readStream", "name": "readStream", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "readStream of SQLContext", "ret_type": "pyspark.sql.streaming.readwriter.DataStreamReader", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "registerDataFrameAsTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "df", "tableName"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.registerDataFrameAsTable", "name": "registerDataFrameAsTable", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "df", "tableName"], "arg_types": ["pyspark.sql.context.SQLContext", "pyspark.sql.dataframe.DataFrame", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "registerDataFrameAsTable of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "registerFunction": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "name", "f", "returnType"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.registerFunction", "name": "registerFunction", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "name", "f", "returnType"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str", {".class": "CallableType", "arg_kinds": [2, 4], "arg_names": [null, null], "arg_types": [{".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": true, "name": null, "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 2}, "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "UnionType", "items": ["pyspark.sql.types.DataType", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "registerFunction of SQLContext", "ret_type": "pyspark.sql._typing.UserDefinedFunctionLike", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "registerJavaFunction": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "name", "javaClassName", "returnType"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.registerJavaFunction", "name": "registerJavaFunction", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0, 1], "arg_names": ["self", "name", "javaClassName", "returnType"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str", "builtins.str", {".class": "UnionType", "items": ["pyspark.sql.types.DataType", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "registerJavaFunction of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "setConf": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.setConf", "name": "setConf", "type": {".class": "CallableType", "arg_kinds": [0, 0, 0], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str", {".class": "UnionType", "items": ["builtins.bool", "builtins.int", "builtins.str"]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "setConf of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "sparkSession": {".class": "SymbolTableNode", "implicit": true, "kind": "Mdef", "node": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.context.SQLContext.sparkSession", "name": "sparkSession", "type": "pyspark.sql.session.SparkSession"}}, "sql": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "sqlQuery"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.sql", "name": "sql", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "sqlQuery"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sql of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "streams": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.streams", "name": "streams", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "streams of SQLContext", "ret_type": "pyspark.sql.streaming.query.StreamingQueryManager", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.streams", "name": "streams", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "streams of SQLContext", "ret_type": "pyspark.sql.streaming.query.StreamingQueryManager", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "table": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.table", "name": "table", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "table of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "tableNames": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1], "arg_names": ["self", "dbName"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.tableNames", "name": "tableNames", "type": {".class": "CallableType", "arg_kinds": [0, 1], "arg_names": ["self", "dbName"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "tableNames of SQLContext", "ret_type": {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "tables": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 1], "arg_names": ["self", "dbName"], "flags": [], "fullname": "pyspark.sql.context.SQLContext.tables", "name": "tables", "type": {".class": "CallableType", "arg_kinds": [0, 1], "arg_names": ["self", "dbName"], "arg_types": ["pyspark.sql.context.SQLContext", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "tables of SQLContext", "ret_type": "pyspark.sql.dataframe.DataFrame", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "udf": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.context.SQLContext.udf", "name": "udf", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "udf of SQLContext", "ret_type": "pyspark.sql.udf.UDFRegistration", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.udf", "name": "udf", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.context.SQLContext"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "udf of SQLContext", "ret_type": "pyspark.sql.udf.UDFRegistration", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "uncacheTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "flags": ["is_decorated"], "fullname": "pyspark.sql.context.SQLContext.uncacheTable", "name": "uncacheTable", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "uncacheTable of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready", "is_inferred"], "fullname": "pyspark.sql.context.SQLContext.uncacheTable", "name": "uncacheTable", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "tableName"], "arg_types": ["pyspark.sql.context.SQLContext", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "uncacheTable of SQLContext", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "SparkContext": {".class": "SymbolTableNode", "cross_ref": "pyspark.context.SparkContext", "kind": "Gdef", "module_public": false}, "SparkSession": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.session.SparkSession", "kind": "Gdef", "module_public": false}, "StreamingQueryManager": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.streaming.query.StreamingQueryManager", "kind": "Gdef", "module_public": false}, "StructType": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.types.StructType", "kind": "Gdef", "module_public": false}, "TYPE_CHECKING": {".class": "SymbolTableNode", "cross_ref": "typing.TYPE_CHECKING", "kind": "Gdef", "module_public": false}, "Tuple": {".class": "SymbolTableNode", "cross_ref": "typing.Tuple", "kind": "Gdef", "module_public": false}, "Type": {".class": "SymbolTableNode", "cross_ref": "typing.Type", "kind": "Gdef", "module_public": false}, "UDFRegistration": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.udf.UDFRegistration", "kind": "Gdef", "module_public": false}, "Union": {".class": "SymbolTableNode", "cross_ref": "typing.Union", "kind": "Gdef", "module_public": false}, "UserDefinedFunctionLike": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql._typing.UserDefinedFunctionLike", "kind": "Gdef", "module_public": false}, "_NoValue": {".class": "SymbolTableNode", "cross_ref": "pyspark._globals._NoValue", "kind": "Gdef", "module_public": false}, "_NoValueType": {".class": "SymbolTableNode", "cross_ref": "pyspark._globals._NoValueType", "kind": "Gdef", "module_public": false}, "__all__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_inferred", "has_explicit_value"], "fullname": "pyspark.sql.context.__all__", "name": "__all__", "type": {".class": "Instance", "args": ["builtins.str"], "type_ref": "builtins.list"}}}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.context.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.context.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.context.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.context.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.context.__package__", "name": "__package__", "type": "builtins.str"}}, "_monkey_patch_RDD": {".class": "SymbolTableNode", "cross_ref": "pyspark.sql.session._monkey_patch_RDD", "kind": "Gdef", "module_public": false}, "_test": {".class": "SymbolTableNode", "kind": "Gdef", "module_public": false, "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [], "arg_names": [], "flags": [], "fullname": "pyspark.sql.context._test", "name": "_test", "type": {".class": "CallableType", "arg_kinds": [], "arg_names": [], "arg_types": [], "bound_args": [], "def_extras": {"first_arg": null}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "_test", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "cast": {".class": "SymbolTableNode", "cross_ref": "typing.cast", "kind": "Gdef", "module_public": false}, "install_exception_handler": {".class": "SymbolTableNode", "cross_ref": "pyspark.errors.exceptions.captured.install_exception_handler", "kind": "Gdef", "module_public": false}, "overload": {".class": "SymbolTableNode", "cross_ref": "typing.overload", "kind": "Gdef", "module_public": false}, "since": {".class": "SymbolTableNode", "cross_ref": "pyspark.since", "kind": "Gdef", "module_public": false}, "sys": {".class": "SymbolTableNode", "cross_ref": "sys", "kind": "Gdef", "module_public": false}, "warnings": {".class": "SymbolTableNode", "cross_ref": "warnings", "kind": "Gdef", "module_public": false}}, "path": "C:\\Users\\Egor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\context.py"}