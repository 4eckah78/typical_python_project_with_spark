{".class": "MypyFile", "_fullname": "pyspark.sql.connect.proto.commands_pb2", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": true, "names": {".class": "SymbolTable", "Command": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.Command", "name": "Command", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.Command", "builtins.object"], "names": {".class": "SymbolTable", "CREATE_DATAFRAME_VIEW_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.CREATE_DATAFRAME_VIEW_FIELD_NUMBER", "name": "CREATE_DATAFRAME_VIEW_FIELD_NUMBER", "type": "builtins.int"}}, "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "command_type"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "command_type"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "create_dataframe_view"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "create_dataframe_view"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "extension"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "extension"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "register_function"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "register_function"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "sql_command"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "sql_command"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "write_operation"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "write_operation"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "write_operation_v2"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "write_operation_v2"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of Command", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "EXTENSION_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.EXTENSION_FIELD_NUMBER", "name": "EXTENSION_FIELD_NUMBER", "type": "builtins.int"}}, "HasField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.HasField", "name": "HasField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "command_type"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "command_type"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "create_dataframe_view"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "create_dataframe_view"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "extension"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "extension"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "register_function"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "register_function"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "sql_command"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "sql_command"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "write_operation"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "write_operation"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "write_operation_v2"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "write_operation_v2"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "HasField of Command", "ret_type": "builtins.bool", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "REGISTER_FUNCTION_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.REGISTER_FUNCTION_FIELD_NUMBER", "name": "REGISTER_FUNCTION_FIELD_NUMBER", "type": "builtins.int"}}, "SQL_COMMAND_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.SQL_COMMAND_FIELD_NUMBER", "name": "SQL_COMMAND_FIELD_NUMBER", "type": "builtins.int"}}, "WRITE_OPERATION_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_FIELD_NUMBER", "name": "WRITE_OPERATION_FIELD_NUMBER", "type": "builtins.int"}}, "WRITE_OPERATION_V2_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_V2_FIELD_NUMBER", "name": "WRITE_OPERATION_V2_FIELD_NUMBER", "type": "builtins.int"}}, "WhichOneof": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.WhichOneof", "name": "WhichOneof", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "command_type"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "command_type"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "WhichOneof of Command", "ret_type": {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "register_function"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "write_operation"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "create_dataframe_view"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "write_operation_v2"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "sql_command"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "extension"}, {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5, 5, 5, 5, 5], "arg_names": ["self", "register_function", "write_operation", "create_dataframe_view", "write_operation_v2", "sql_command", "extension"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5, 5, 5, 5, 5], "arg_names": ["self", "register_function", "write_operation", "create_dataframe_view", "write_operation_v2", "sql_command", "extension"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command", {".class": "UnionType", "items": ["pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of Command", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "create_dataframe_view": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.create_dataframe_view", "name": "create_dataframe_view", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "create_dataframe_view of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.create_dataframe_view", "name": "create_dataframe_view", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "create_dataframe_view of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "extension": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.extension", "name": "extension", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "extension of Command", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.extension", "name": "extension", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "extension of Command", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "register_function": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.register_function", "name": "register_function", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "register_function of Command", "ret_type": "pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.register_function", "name": "register_function", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "register_function of Command", "ret_type": "pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "sql_command": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.sql_command", "name": "sql_command", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sql_command of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.SqlCommand", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.sql_command", "name": "sql_command", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sql_command of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.SqlCommand", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "write_operation": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.write_operation", "name": "write_operation", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "write_operation of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.write_operation", "name": "write_operation", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "write_operation of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "write_operation_v2": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.write_operation_v2", "name": "write_operation_v2", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "write_operation_v2 of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.Command.write_operation_v2", "name": "write_operation_v2", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.Command"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "write_operation_v2 of Command", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "CreateDataFrameViewCommand": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", "name": "CreateDataFrameViewCommand", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", "builtins.object"], "names": {".class": "SymbolTable", "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "is_global"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "is_global"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "name"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "name"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "replace"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "replace"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of CreateDataFrameViewCommand", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "HasField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.HasField", "name": "HasField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "input"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "HasField of CreateDataFrameViewCommand", "ret_type": "builtins.bool", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "INPUT_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.INPUT_FIELD_NUMBER", "name": "INPUT_FIELD_NUMBER", "type": "builtins.int"}}, "IS_GLOBAL_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.IS_GLOBAL_FIELD_NUMBER", "name": "IS_GLOBAL_FIELD_NUMBER", "type": "builtins.int"}}, "NAME_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.NAME_FIELD_NUMBER", "name": "NAME_FIELD_NUMBER", "type": "builtins.int"}}, "REPLACE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.REPLACE_FIELD_NUMBER", "name": "REPLACE_FIELD_NUMBER", "type": "builtins.int"}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5, 5, 5], "arg_names": ["self", "input", "name", "is_global", "replace"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5, 5, 5], "arg_names": ["self", "input", "name", "is_global", "replace"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand", {".class": "UnionType", "items": ["pyspark.sql.connect.proto.relations_pb2.Relation", {".class": "NoneType"}]}, "builtins.str", "builtins.bool", "builtins.bool"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of CreateDataFrameViewCommand", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "input": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.input", "name": "input", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "input of CreateDataFrameViewCommand", "ret_type": "pyspark.sql.connect.proto.relations_pb2.Relation", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.input", "name": "input", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "input of CreateDataFrameViewCommand", "ret_type": "pyspark.sql.connect.proto.relations_pb2.Relation", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "is_global": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.is_global", "name": "is_global", "type": "builtins.bool"}}, "name": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.name", "name": "name", "type": "builtins.str"}}, "replace": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.replace", "name": "replace", "type": "builtins.bool"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "SqlCommand": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand", "name": "SqlCommand", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand", "builtins.object"], "names": {".class": "SymbolTable", "ARGS_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ARGS_FIELD_NUMBER", "name": "ARGS_FIELD_NUMBER", "type": "builtins.int"}}, "ArgsEntry": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry", "name": "ArgsEntry", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry", "builtins.object"], "names": {".class": "SymbolTable", "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "value"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "value"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of ArgsEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "HasField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.HasField", "name": "HasField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "value"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "value"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "HasField of ArgsEntry", "ret_type": "builtins.bool", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "KEY_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.KEY_FIELD_NUMBER", "name": "KEY_FIELD_NUMBER", "type": "builtins.int"}}, "VALUE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.VALUE_FIELD_NUMBER", "name": "VALUE_FIELD_NUMBER", "type": "builtins.int"}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry", "builtins.str", {".class": "UnionType", "items": ["pyspark.sql.connect.proto.expressions_pb2.Expression.Literal", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of ArgsEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "key": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.key", "name": "key", "type": "builtins.str"}}, "value": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.value", "name": "value", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "value of ArgsEntry", "ret_type": "pyspark.sql.connect.proto.expressions_pb2.Expression.Literal", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.value", "name": "value", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "value of ArgsEntry", "ret_type": "pyspark.sql.connect.proto.expressions_pb2.Expression.Literal", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "args"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "args"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "sql"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "sql"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of SqlCommand", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "SQL_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.SQL_FIELD_NUMBER", "name": "SQL_FIELD_NUMBER", "type": "builtins.int"}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5], "arg_names": ["self", "sql", "args"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5], "arg_names": ["self", "sql", "args"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand", "builtins.str", {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"], "type_ref": "typing.Mapping"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of SqlCommand", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "args": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.args", "name": "args", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "args of SqlCommand", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.args", "name": "args", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.SqlCommand"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "args of SqlCommand", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "sql": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.SqlCommand.sql", "name": "sql", "type": "builtins.str"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "WriteOperation": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation", "name": "WriteOperation", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", "builtins.object"], "names": {".class": "SymbolTable", "BUCKET_BY_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BUCKET_BY_FIELD_NUMBER", "name": "BUCKET_BY_FIELD_NUMBER", "type": "builtins.int"}}, "BucketBy": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", "name": "BucketBy", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", "builtins.object"], "names": {".class": "SymbolTable", "BUCKET_COLUMN_NAMES_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.BUCKET_COLUMN_NAMES_FIELD_NUMBER", "name": "BUCKET_COLUMN_NAMES_FIELD_NUMBER", "type": "builtins.int"}}, "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "bucket_column_names"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "bucket_column_names"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "num_buckets"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "num_buckets"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of BucketBy", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "NUM_BUCKETS_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.NUM_BUCKETS_FIELD_NUMBER", "name": "NUM_BUCKETS_FIELD_NUMBER", "type": "builtins.int"}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5], "arg_names": ["self", "bucket_column_names", "num_buckets"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5], "arg_names": ["self", "bucket_column_names", "num_buckets"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str"], "type_ref": "typing.Iterable"}, {".class": "NoneType"}]}, "builtins.int"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of BucketBy", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "bucket_column_names": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.bucket_column_names", "name": "bucket_column_names", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucket_column_names of BucketBy", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.bucket_column_names", "name": "bucket_column_names", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucket_column_names of BucketBy", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "num_buckets": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.num_buckets", "name": "num_buckets", "type": "builtins.int"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "_source"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "_source"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "bucket_by"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "bucket_by"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "mode"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "mode"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "options"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "options"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "partitioning_columns"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "partitioning_columns"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "path"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "path"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "save_type"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "save_type"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "sort_column_names"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "sort_column_names"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "source"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "source"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "table"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "table"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of WriteOperation", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "HasField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.HasField", "name": "HasField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "_source"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "_source"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "bucket_by"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "bucket_by"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "path"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "path"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "save_type"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "save_type"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "source"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "source"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "table"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "table"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "HasField of WriteOperation", "ret_type": "builtins.bool", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "INPUT_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.INPUT_FIELD_NUMBER", "name": "INPUT_FIELD_NUMBER", "type": "builtins.int"}}, "MODE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.MODE_FIELD_NUMBER", "name": "MODE_FIELD_NUMBER", "type": "builtins.int"}}, "OPTIONS_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OPTIONS_FIELD_NUMBER", "name": "OPTIONS_FIELD_NUMBER", "type": "builtins.int"}}, "OptionsEntry": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry", "name": "OptionsEntry", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry", "builtins.object"], "names": {".class": "SymbolTable", "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "value"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "value"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of OptionsEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "KEY_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.KEY_FIELD_NUMBER", "name": "KEY_FIELD_NUMBER", "type": "builtins.int"}}, "VALUE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.VALUE_FIELD_NUMBER", "name": "VALUE_FIELD_NUMBER", "type": "builtins.int"}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of OptionsEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "key": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.key", "name": "key", "type": "builtins.str"}}, "value": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.value", "name": "value", "type": "builtins.str"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "PARTITIONING_COLUMNS_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.PARTITIONING_COLUMNS_FIELD_NUMBER", "name": "PARTITIONING_COLUMNS_FIELD_NUMBER", "type": "builtins.int"}}, "PATH_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.PATH_FIELD_NUMBER", "name": "PATH_FIELD_NUMBER", "type": "builtins.int"}}, "SAVE_MODE_APPEND": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_APPEND", "name": "SAVE_MODE_APPEND", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_ERROR_IF_EXISTS": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_ERROR_IF_EXISTS", "name": "SAVE_MODE_ERROR_IF_EXISTS", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_IGNORE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_IGNORE", "name": "SAVE_MODE_IGNORE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_OVERWRITE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_OVERWRITE", "name": "SAVE_MODE_OVERWRITE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_UNSPECIFIED": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_UNSPECIFIED", "name": "SAVE_MODE_UNSPECIFIED", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SORT_COLUMN_NAMES_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SORT_COLUMN_NAMES_FIELD_NUMBER", "name": "SORT_COLUMN_NAMES_FIELD_NUMBER", "type": "builtins.int"}}, "SOURCE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SOURCE_FIELD_NUMBER", "name": "SOURCE_FIELD_NUMBER", "type": "builtins.int"}}, "SaveMode": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode"], "declared_metaclass": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper", "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveMode", "name": "SaveMode", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveMode", "has_param_spec_type": false, "metaclass_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper", "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveMode", "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode", "builtins.object"], "names": {".class": "SymbolTable"}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "SaveTable": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", "name": "SaveTable", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", "builtins.object"], "names": {".class": "SymbolTable", "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "save_method"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "save_method"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "table_name"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "table_name"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of SaveTable", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "SAVE_METHOD_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.SAVE_METHOD_FIELD_NUMBER", "name": "SAVE_METHOD_FIELD_NUMBER", "type": "builtins.int"}}, "TABLE_NAME_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_NAME_FIELD_NUMBER", "name": "TABLE_NAME_FIELD_NUMBER", "type": "builtins.int"}}, "TABLE_SAVE_METHOD_INSERT_INTO": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_INSERT_INTO", "name": "TABLE_SAVE_METHOD_INSERT_INTO", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}, "TABLE_SAVE_METHOD_SAVE_AS_TABLE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_SAVE_AS_TABLE", "name": "TABLE_SAVE_METHOD_SAVE_AS_TABLE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}, "TABLE_SAVE_METHOD_UNSPECIFIED": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_UNSPECIFIED", "name": "TABLE_SAVE_METHOD_UNSPECIFIED", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}, "TableSaveMethod": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod"], "declared_metaclass": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper", "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TableSaveMethod", "name": "TableSaveMethod", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TableSaveMethod", "has_param_spec_type": false, "metaclass_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper", "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TableSaveMethod", "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod", "builtins.object"], "names": {".class": "SymbolTable"}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "_TableSaveMethod": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod", "name": "_TableSaveMethod", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod", "builtins.object"], "names": {".class": "SymbolTable", "V": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 12, "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.V", "line": 298, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}, "ValueType": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.int"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType", "name": "ValueType", "type_vars": []}, "deletable_attributes": [], "flags": ["is_newtype"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType", "builtins.int", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "item"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "item"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType", "builtins.int"], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of ValueType", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "_TableSaveMethodEnumTypeWrapper": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.type"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper", "name": "_TableSaveMethodEnumTypeWrapper", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper", "builtins.type", "builtins.object"], "names": {".class": "SymbolTable", "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "TABLE_SAVE_METHOD_INSERT_INTO": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_INSERT_INTO", "name": "TABLE_SAVE_METHOD_INSERT_INTO", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}, "TABLE_SAVE_METHOD_SAVE_AS_TABLE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_SAVE_AS_TABLE", "name": "TABLE_SAVE_METHOD_SAVE_AS_TABLE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}, "TABLE_SAVE_METHOD_UNSPECIFIED": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_UNSPECIFIED", "name": "TABLE_SAVE_METHOD_UNSPECIFIED", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5], "arg_names": ["self", "table_name", "save_method"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5], "arg_names": ["self", "table_name", "save_method"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", "builtins.str", "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of SaveTable", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "save_method": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.save_method", "name": "save_method", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"}}, "table_name": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.table_name", "name": "table_name", "type": "builtins.str"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "TABLE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.TABLE_FIELD_NUMBER", "name": "TABLE_FIELD_NUMBER", "type": "builtins.int"}}, "WhichOneof": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "OverloadedFuncDef", "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof", "impl": null, "items": [{".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof", "name": "WhichOneof", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "_source"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "_source"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "WhichOneof of WriteOperation", "ret_type": {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "source"}, {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof", "name": "WhichOneof", "type": null}}, {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "flags": ["is_overload", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof", "name": "WhichOneof", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "save_type"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "save_type"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "WhichOneof of WriteOperation", "ret_type": {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "path"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "table"}, {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": true, "var": {".class": "Var", "flags": ["is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof", "name": "WhichOneof", "type": null}}], "type": {".class": "Overloaded", "items": [{".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "_source"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "_source"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "WhichOneof of WriteOperation", "ret_type": {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "source"}, {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}, {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "save_type"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "save_type"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "WhichOneof of WriteOperation", "ret_type": {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "path"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "table"}, {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}]}}}, "_SaveMode": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode", "name": "_SaveMode", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode", "builtins.object"], "names": {".class": "SymbolTable", "V": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 8, "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.V", "line": 254, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "ValueType": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.int"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType", "name": "ValueType", "type_vars": []}, "deletable_attributes": [], "flags": ["is_newtype"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType", "builtins.int", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "item"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "item"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType", "builtins.int"], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of ValueType", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "_SaveModeEnumTypeWrapper": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.type"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper", "name": "_SaveModeEnumTypeWrapper", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper", "builtins.type", "builtins.object"], "names": {".class": "SymbolTable", "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "SAVE_MODE_APPEND": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_APPEND", "name": "SAVE_MODE_APPEND", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_ERROR_IF_EXISTS": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_ERROR_IF_EXISTS", "name": "SAVE_MODE_ERROR_IF_EXISTS", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_IGNORE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_IGNORE", "name": "SAVE_MODE_IGNORE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_OVERWRITE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_OVERWRITE", "name": "SAVE_MODE_OVERWRITE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "SAVE_MODE_UNSPECIFIED": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_UNSPECIFIED", "name": "SAVE_MODE_UNSPECIFIED", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5, 5, 5, 5, 5, 5, 5, 5], "arg_names": ["self", "input", "source", "path", "table", "mode", "sort_column_names", "partitioning_columns", "bucket_by", "options"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5, 5, 5, 5, 5, 5, 5, 5], "arg_names": ["self", "input", "source", "path", "table", "mode", "sort_column_names", "partitioning_columns", "bucket_by", "options"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation", {".class": "UnionType", "items": ["pyspark.sql.connect.proto.relations_pb2.Relation", {".class": "NoneType"}]}, {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, "builtins.str", {".class": "UnionType", "items": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", {".class": "NoneType"}]}, "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType", {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str"], "type_ref": "typing.Iterable"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str"], "type_ref": "typing.Iterable"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "typing.Mapping"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of WriteOperation", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "bucket_by": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.bucket_by", "name": "bucket_by", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucket_by of WriteOperation", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.bucket_by", "name": "bucket_by", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "bucket_by of WriteOperation", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "input": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.input", "name": "input", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "input of WriteOperation", "ret_type": "pyspark.sql.connect.proto.relations_pb2.Relation", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.input", "name": "input", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "input of WriteOperation", "ret_type": "pyspark.sql.connect.proto.relations_pb2.Relation", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "mode": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.mode", "name": "mode", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"}}, "options": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.options", "name": "options", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "options of WriteOperation", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.options", "name": "options", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "options of WriteOperation", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "partitioning_columns": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.partitioning_columns", "name": "partitioning_columns", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitioning_columns of WriteOperation", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.partitioning_columns", "name": "partitioning_columns", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitioning_columns of WriteOperation", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "path": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.path", "name": "path", "type": "builtins.str"}}, "sort_column_names": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.sort_column_names", "name": "sort_column_names", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sort_column_names of WriteOperation", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.sort_column_names", "name": "sort_column_names", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "sort_column_names of WriteOperation", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "source": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.source", "name": "source", "type": "builtins.str"}}, "table": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.table", "name": "table", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "table of WriteOperation", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.table", "name": "table", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "table of WriteOperation", "ret_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "WriteOperationV2": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", "name": "WriteOperationV2", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", "builtins.object"], "names": {".class": "SymbolTable", "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "_provider"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "_provider"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "mode"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "mode"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "options"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "options"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "overwrite_condition"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "overwrite_condition"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "partitioning_columns"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "partitioning_columns"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "provider"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "provider"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "table_name"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "table_name"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "table_properties"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "table_properties"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of WriteOperationV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "HasField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.HasField", "name": "HasField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "_provider"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "_provider"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "input"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "overwrite_condition"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "overwrite_condition"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "provider"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "provider"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "HasField of WriteOperationV2", "ret_type": "builtins.bool", "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "INPUT_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.INPUT_FIELD_NUMBER", "name": "INPUT_FIELD_NUMBER", "type": "builtins.int"}}, "MODE_APPEND": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_APPEND", "name": "MODE_APPEND", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_CREATE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATE", "name": "MODE_CREATE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_CREATE_OR_REPLACE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATE_OR_REPLACE", "name": "MODE_CREATE_OR_REPLACE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_FIELD_NUMBER", "name": "MODE_FIELD_NUMBER", "type": "builtins.int"}}, "MODE_OVERWRITE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITE", "name": "MODE_OVERWRITE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_OVERWRITE_PARTITIONS": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITE_PARTITIONS", "name": "MODE_OVERWRITE_PARTITIONS", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_REPLACE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_REPLACE", "name": "MODE_REPLACE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_UNSPECIFIED": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_UNSPECIFIED", "name": "MODE_UNSPECIFIED", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "Mode": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode"], "declared_metaclass": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper", "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.Mode", "name": "Mode", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.Mode", "has_param_spec_type": false, "metaclass_type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper", "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.Mode", "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode", "builtins.object"], "names": {".class": "SymbolTable"}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "OPTIONS_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OPTIONS_FIELD_NUMBER", "name": "OPTIONS_FIELD_NUMBER", "type": "builtins.int"}}, "OVERWRITE_CONDITION_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OVERWRITE_CONDITION_FIELD_NUMBER", "name": "OVERWRITE_CONDITION_FIELD_NUMBER", "type": "builtins.int"}}, "OptionsEntry": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry", "name": "OptionsEntry", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry", "builtins.object"], "names": {".class": "SymbolTable", "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "value"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "value"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of OptionsEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "KEY_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.KEY_FIELD_NUMBER", "name": "KEY_FIELD_NUMBER", "type": "builtins.int"}}, "VALUE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.VALUE_FIELD_NUMBER", "name": "VALUE_FIELD_NUMBER", "type": "builtins.int"}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of OptionsEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "key": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.key", "name": "key", "type": "builtins.str"}}, "value": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.value", "name": "value", "type": "builtins.str"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "PARTITIONING_COLUMNS_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PARTITIONING_COLUMNS_FIELD_NUMBER", "name": "PARTITIONING_COLUMNS_FIELD_NUMBER", "type": "builtins.int"}}, "PROVIDER_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PROVIDER_FIELD_NUMBER", "name": "PROVIDER_FIELD_NUMBER", "type": "builtins.int"}}, "TABLE_NAME_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_NAME_FIELD_NUMBER", "name": "TABLE_NAME_FIELD_NUMBER", "type": "builtins.int"}}, "TABLE_PROPERTIES_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_PROPERTIES_FIELD_NUMBER", "name": "TABLE_PROPERTIES_FIELD_NUMBER", "type": "builtins.int"}}, "TablePropertiesEntry": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry", "name": "TablePropertiesEntry", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry", "builtins.object"], "names": {".class": "SymbolTable", "ClearField": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.ClearField", "name": "ClearField", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "field_name"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "key"}, {".class": "LiteralType", "fallback": "builtins.str", "value": "value"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "value"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "ClearField of TablePropertiesEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "KEY_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.KEY_FIELD_NUMBER", "name": "KEY_FIELD_NUMBER", "type": "builtins.int"}}, "VALUE_FIELD_NUMBER": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.VALUE_FIELD_NUMBER", "name": "VALUE_FIELD_NUMBER", "type": "builtins.int"}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5], "arg_names": ["self", "key", "value"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry", "builtins.str", "builtins.str"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of TablePropertiesEntry", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "key": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.key", "name": "key", "type": "builtins.str"}}, "value": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.value", "name": "value", "type": "builtins.str"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "WhichOneof": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.WhichOneof", "name": "WhichOneof", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "oneof_group"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "_provider"}, {".class": "LiteralType", "fallback": "builtins.bytes", "value": "_provider"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "WhichOneof of WriteOperationV2", "ret_type": {".class": "UnionType", "items": [{".class": "LiteralType", "fallback": "builtins.str", "value": "provider"}, {".class": "NoneType"}]}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "_Mode": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.object"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode", "name": "_Mode", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode", "builtins.object"], "names": {".class": "SymbolTable", "V": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 8, "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.V", "line": 472, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "ValueType": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.int"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType", "name": "ValueType", "type_vars": []}, "deletable_attributes": [], "flags": ["is_newtype"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType", "builtins.int", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 0], "arg_names": ["self", "item"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "item"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType", "builtins.int"], "bound_args": [], "def_extras": {}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of ValueType", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "_ModeEnumTypeWrapper": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "TypeInfo", "_promote": [], "abstract_attributes": [], "bases": ["builtins.type"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper", "name": "_ModeEnumTypeWrapper", "type_vars": []}, "deletable_attributes": [], "flags": ["fallback_to_any"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "pyspark.sql.connect.proto.commands_pb2", "mro": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper", "builtins.type", "builtins.object"], "names": {".class": "SymbolTable", "DESCRIPTOR": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.DESCRIPTOR", "name": "DESCRIPTOR", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "MODE_APPEND": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_APPEND", "name": "MODE_APPEND", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_CREATE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_CREATE", "name": "MODE_CREATE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_CREATE_OR_REPLACE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_CREATE_OR_REPLACE", "name": "MODE_CREATE_OR_REPLACE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_OVERWRITE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_OVERWRITE", "name": "MODE_OVERWRITE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_OVERWRITE_PARTITIONS": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_OVERWRITE_PARTITIONS", "name": "MODE_OVERWRITE_PARTITIONS", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_REPLACE": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_REPLACE", "name": "MODE_REPLACE", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "MODE_UNSPECIFIED": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_UNSPECIFIED", "name": "MODE_UNSPECIFIED", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0, 5, 5, 5, 5, 5, 5, 5, 5], "arg_names": ["self", "input", "table_name", "provider", "partitioning_columns", "options", "table_properties", "mode", "overwrite_condition"], "flags": [], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.__init__", "name": "__init__", "type": {".class": "CallableType", "arg_kinds": [0, 5, 5, 5, 5, 5, 5, 5, 5], "arg_names": ["self", "input", "table_name", "provider", "partitioning_columns", "options", "table_properties", "mode", "overwrite_condition"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2", {".class": "UnionType", "items": ["pyspark.sql.connect.proto.relations_pb2.Relation", {".class": "NoneType"}]}, "builtins.str", {".class": "UnionType", "items": ["builtins.str", {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["pyspark.sql.connect.proto.expressions_pb2.Expression"], "type_ref": "typing.Iterable"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "typing.Mapping"}, {".class": "NoneType"}]}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "typing.Mapping"}, {".class": "NoneType"}]}, "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType", {".class": "UnionType", "items": ["pyspark.sql.connect.proto.expressions_pb2.Expression", {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "__init__ of WriteOperationV2", "ret_type": {".class": "NoneType"}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}, "input": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.input", "name": "input", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "input of WriteOperationV2", "ret_type": "pyspark.sql.connect.proto.relations_pb2.Relation", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.input", "name": "input", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "input of WriteOperationV2", "ret_type": "pyspark.sql.connect.proto.relations_pb2.Relation", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "mode": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.mode", "name": "mode", "type": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"}}, "options": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.options", "name": "options", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "options of WriteOperationV2", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.options", "name": "options", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "options of WriteOperationV2", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "overwrite_condition": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.overwrite_condition", "name": "overwrite_condition", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "overwrite_condition of WriteOperationV2", "ret_type": "pyspark.sql.connect.proto.expressions_pb2.Expression", "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.overwrite_condition", "name": "overwrite_condition", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "overwrite_condition of WriteOperationV2", "ret_type": "pyspark.sql.connect.proto.expressions_pb2.Expression", "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "partitioning_columns": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.partitioning_columns", "name": "partitioning_columns", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitioning_columns of WriteOperationV2", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.partitioning_columns", "name": "partitioning_columns", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "partitioning_columns of WriteOperationV2", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}, "provider": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.provider", "name": "provider", "type": "builtins.str"}}, "table_name": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_name", "name": "table_name", "type": "builtins.str"}}, "table_properties": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "abstract_status": 0, "arg_kinds": [0], "arg_names": ["self"], "flags": ["is_property", "is_decorated"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_properties", "name": "table_properties", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "table_properties of WriteOperationV2", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_property", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_properties", "name": "table_properties", "type": {".class": "CallableType", "arg_kinds": [0], "arg_names": ["self"], "arg_types": ["pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": false, "is_ellipsis_args": false, "name": "table_properties of WriteOperationV2", "ret_type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}, "type_guard": null, "unpack_kwargs": false, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "pyspark.sql.connect.proto.commands_pb2.__package__", "name": "__package__", "type": "builtins.str"}}, "builtins": {".class": "SymbolTableNode", "cross_ref": "builtins", "kind": "Gdef", "module_hidden": true, "module_public": false}, "collections": {".class": "SymbolTableNode", "cross_ref": "collections", "kind": "Gdef", "module_hidden": true, "module_public": false}, "global___Command": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 0, "fullname": "pyspark.sql.connect.proto.commands_pb2.global___Command", "line": 145, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.Command"}}, "global___CreateDataFrameViewCommand": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 0, "fullname": "pyspark.sql.connect.proto.commands_pb2.global___CreateDataFrameViewCommand", "line": 245, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"}}, "global___SqlCommand": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 0, "fullname": "pyspark.sql.connect.proto.commands_pb2.global___SqlCommand", "line": 203, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.SqlCommand"}}, "global___WriteOperation": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 0, "fullname": "pyspark.sql.connect.proto.commands_pb2.global___WriteOperation", "line": 463, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.WriteOperation"}}, "global___WriteOperationV2": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeAlias", "alias_tvars": [], "column": 0, "fullname": "pyspark.sql.connect.proto.commands_pb2.global___WriteOperationV2", "line": 626, "no_args": true, "normalized": false, "target": "pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"}}, "google": {".class": "SymbolTableNode", "kind": "Gdef", "module_hidden": true, "module_public": false, "node": {".class": "Var", "flags": ["is_suppressed_import", "is_ready", "is_inferred"], "fullname": "pyspark.sql.connect.proto.commands_pb2.google", "name": "google", "type": {".class": "AnyType", "missing_import_name": "pyspark.sql.connect.proto.commands_pb2.google", "source_any": null, "type_of_any": 3}}}, "pyspark": {".class": "SymbolTableNode", "cross_ref": "pyspark", "kind": "Gdef", "module_hidden": true, "module_public": false}, "sys": {".class": "SymbolTableNode", "cross_ref": "sys", "kind": "Gdef", "module_hidden": true, "module_public": false}, "typing": {".class": "SymbolTableNode", "cross_ref": "typing", "kind": "Gdef", "module_hidden": true, "module_public": false}, "typing_extensions": {".class": "SymbolTableNode", "cross_ref": "typing", "kind": "Gdef", "module_hidden": true, "module_public": false}}, "path": "C:\\Users\\Egor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\connect\\proto\\commands_pb2.pyi"}